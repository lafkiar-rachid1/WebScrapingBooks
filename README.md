# ğŸ“š WebScrapingBooks - Books to Scrape Dashboard

Un projet de web scraping et d'analyse de donnÃ©es de livres provenant du site [Books to Scrape](http://books.toscrape.com/), avec un dashboard interactif construit avec Streamlit.

## ğŸ¯ Objectif du Projet

Ce projet permet de :
- Scraper automatiquement les donnÃ©es de livres (titre, prix, notation, disponibilitÃ©, etc.)
- Sauvegarder les donnÃ©es dans un fichier CSV
- Visualiser et analyser les donnÃ©es Ã  travers un dashboard interactif
- Explorer les relations entre prix et notations
- Filtrer et tÃ©lÃ©charger les donnÃ©es

## âœ¨ FonctionnalitÃ©s

### Web Scraper (`scraper.py`)
- âœ… Scraping multi-pages automatique
- âœ… Extraction de donnÃ©es dÃ©taillÃ©es pour chaque livre :
  - Titre, prix, notation
  - DisponibilitÃ©
  - URL du livre et de l'image
  - UPC (Universal Product Code)
  - Nombre d'avis
  - Description complÃ¨te
- âœ… Sauvegarde automatique en CSV
- âœ… Gestion d'erreurs robuste

### Dashboard Analytique (`dashboard.py`)
- ğŸ“Š **Statistiques gÃ©nÃ©rales** : nombre de livres, prix moyen, notation moyenne
- ğŸ“ˆ **Visualisations interactives** :
  - Distribution des prix (histogramme et box plot)
  - RÃ©partition des notations (bar chart et pie chart)
  - Analyse de corrÃ©lation prix vs notation (scatter plot)
  - Top 10 des livres les mieux notÃ©s et les plus chers
- ğŸ–¼ï¸ **Galerie de livres** avec images
- ğŸ” **Filtrage dynamique** par prix et notation
- ğŸ’¾ **Export des donnÃ©es filtrÃ©es** en CSV

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3.x**
- **Web Scraping** :
  - `requests` - RequÃªtes HTTP
  - `BeautifulSoup4` - Parsing HTML
- **Data Analysis** :
  - `pandas` - Manipulation de donnÃ©es
- **Visualisation** :
  - `streamlit` - Dashboard interactif
  - `plotly` - Graphiques interactifs
- **Utilities** :
  - `urllib` - Gestion des URLs

## ğŸ“‹ PrÃ©requis

- Python 3.7 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

## ğŸš€ Installation

1. **Cloner le repository**
```bash
git clone https://github.com/lafkiar-rachid1/WebScrapingBooks.git
cd WebScrapingBooks
```

2. **CrÃ©er un environnement virtuel (recommandÃ©)**
```bash
python -m venv venv

# Sur Windows
venv\Scripts\activate

# Sur macOS/Linux
source venv/bin/activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

## ğŸ’» Utilisation

### Option 1 : Scraping uniquement

Pour scraper les donnÃ©es et les sauvegarder en CSV :

```bash
python scraper.py
```

Cela crÃ©era un fichier `books_data.csv` avec les donnÃ©es de 5 pages (modifiable dans le code).

### Option 2 : Dashboard interactif

Pour lancer le dashboard Streamlit :

```bash
streamlit run dashboard.py
```

Le dashboard s'ouvrira automatiquement dans votre navigateur par dÃ©faut.

### FonctionnalitÃ©s du Dashboard

1. **Charger des donnÃ©es existantes** : Utilise le fichier `books_data.csv` existant
2. **Nouveau scraping** : Lance un nouveau scraping avec un nombre de pages personnalisable
3. **Visualisations** : Explorez diffÃ©rents graphiques et analyses
4. **Filtrage** : Filtrez les livres par prix et notation
5. **Export** : TÃ©lÃ©chargez les donnÃ©es filtrÃ©es en CSV

## ğŸ“ Structure du Projet

```
webScrapingbooks/
â”‚
â”œâ”€â”€ scraper.py              # Script de web scraping
â”œâ”€â”€ dashboard.py            # Application Streamlit
â”œâ”€â”€ books_data.csv          # DonnÃ©es scrapÃ©es (gÃ©nÃ©rÃ©)
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ README.md              # Ce fichier
â”‚
â””â”€â”€ __pycache__/           # Cache Python (ignorÃ©)
```

## ğŸ“Š Exemple de DonnÃ©es

Le scraper collecte les informations suivantes pour chaque livre :

| Colonne | Description | Exemple |
|---------|-------------|---------|
| titre | Titre du livre | "A Light in the Attic" |
| prix | Prix en livres sterling | 51.77 |
| notation | Note sur 5 Ã©toiles | 3 |
| disponibilite | Statut de disponibilitÃ© | "In stock" |
| url | Lien vers la page du livre | http://books.toscrape.com/... |
| image_url | URL de l'image de couverture | http://books.toscrape.com/media/... |
| upc | Code produit universel | a897fe39b1053632 |
| avis | Nombre d'avis | 0 |
| description | Description complÃ¨te du livre | "It's hard to imagine..." |

## ğŸ“ˆ Analyses Disponibles

Le dashboard offre plusieurs types d'analyses :

- **Distribution des prix** : Identifiez les tendances de prix
- **RÃ©partition des notations** : Comprenez la qualitÃ© globale du catalogue
- **CorrÃ©lation prix/notation** : Analysez si les livres chers sont mieux notÃ©s
- **Tops** : DÃ©couvrez les meilleurs livres et les plus chers
- **Statistiques filtrÃ©es** : Analyses personnalisÃ©es selon vos critÃ¨res

## âš™ï¸ Configuration

### Modifier le nombre de pages Ã  scraper

Dans `scraper.py`, ligne finale :
```python
scraper.scrape_all_pages(max_pages=5)  # Changez ce nombre
```

### Personnaliser le dÃ©lai entre les requÃªtes

Dans `scraper.py`, mÃ©thode `scrape_all_pages()` :
```python
time.sleep(0.5)  # Augmentez pour rÃ©duire la charge sur le serveur
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
1. Fork le projet
2. CrÃ©er une branche pour votre fonctionnalitÃ© (`git checkout -b feature/AmazingFeature`)
3. Commit vos changements (`git commit -m 'Add some AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ Notes

- Le site [Books to Scrape](http://books.toscrape.com/) est un site d'entraÃ®nement spÃ©cialement conÃ§u pour apprendre le web scraping
- Respectez toujours les dÃ©lais entre les requÃªtes pour ne pas surcharger le serveur
- Les donnÃ©es sont Ã  usage Ã©ducatif uniquement

## ğŸ› ProblÃ¨mes Connus

- Si le scraping Ã©choue, vÃ©rifiez votre connexion internet
- Certaines pages peuvent mettre du temps Ã  charger, soyez patient
- Si le dashboard ne s'affiche pas correctement, essayez de relancer Streamlit

## ğŸ“§ Contact

**Rachid LAFKIAR**
- GitHub: [@lafkiar-rachid1](https://github.com/lafkiar-rachid1)

## ğŸ“„ License

Ce projet est sous licence MIT - voir le fichier LICENSE pour plus de dÃ©tails.

## ğŸ™ Remerciements

- [Books to Scrape](http://books.toscrape.com/) pour fournir un site d'entraÃ®nement au web scraping
- La communautÃ© Streamlit pour les excellents outils de visualisation
- Tous les contributeurs qui ont aidÃ© Ã  amÃ©liorer ce projet

---

â­ **Si ce projet vous a Ã©tÃ© utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !**
