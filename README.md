# ğŸ“š WebScrapingBooks - Books to Scrape Dashboard

Un projet de web scraping et d'analyse de donnÃ©es de livres provenant du site [Books to Scrape](http://books.toscrape.com/), avec un dashboard interactif construit avec Streamlit.

## ğŸ¯ Objectif du Projet

Ce projet permet de :
- Scraper automatiquement les donnÃ©es de livres (titre, prix, notation, disponibilitÃ©, etc.)
- Sauvegarder les donnÃ©es dans un fichier CSV
- Visualiser et analyser les donnÃ©es Ã  travers un dashboard interactif
- Explorer les relations entre prix et notations
- Filtrer et tÃ©lÃ©charger les donnÃ©es

## âœ¨ FonctionnalitÃ©s

### Web Scraper (`scraper.py`)
- âœ… Scraping multi-pages automatique
- âœ… Extraction de donnÃ©es dÃ©taillÃ©es pour chaque livre :
  - Titre, prix, notation
  - DisponibilitÃ©
  - URL du livre et de l'image
  - UPC (Universal Product Code)
  - Nombre d'avis
  - Description complÃ¨te
- âœ… Sauvegarde automatique en CSV
- âœ… Gestion d'erreurs robuste

### Dashboard Analytique (`dashboard.py`)
- ğŸ“Š **Statistiques gÃ©nÃ©rales** : nombre de livres, prix moyen, notation moyenne
- ğŸ“ˆ **Visualisations interactives** :
  - Distribution des prix (histogramme et box plot)
  - RÃ©partition des notations (bar chart et pie chart)
  - Analyse de corrÃ©lation prix vs notation (scatter plot)
  - Top 10 des livres les mieux notÃ©s et les plus chers
- ğŸ–¼ï¸ **Galerie de livres** avec images
- ğŸ” **Filtrage dynamique** par prix et notation
- ğŸ’¾ **Export des donnÃ©es filtrÃ©es** en CSV

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3.x**
- **Web Scraping** :
  - `requests` - RequÃªtes HTTP
  - `BeautifulSoup4` - Parsing HTML
- **Data Analysis** :
  - `pandas` - Manipulation de donnÃ©es
- **Visualisation** :
  - `streamlit` - Dashboard interactif
  - `plotly` - Graphiques interactifs
- **Utilities** :
  - `urllib` - Gestion des URLs

## ğŸ“‹ PrÃ©requis

- Python 3.7 ou supÃ©rieur
- pip (gestionnaire de paquets Python)

## ğŸš€ Installation

1. **Cloner le repository**
```bash
git clone https://github.com/lafkiar-rachid1/WebScrapingBooks.git
cd WebScrapingBooks
```

2. **CrÃ©er un environnement virtuel (recommandÃ©)**
```bash
python -m venv venv

# Sur Windows
venv\Scripts\activate

# Sur macOS/Linux
source venv/bin/activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

## ğŸ’» Utilisation

### Option 1 : Scraping uniquement

Pour scraper les donnÃ©es et les sauvegarder en CSV :

```bash
python scraper.py
```

Cela crÃ©era un fichier `books_data.csv` avec les donnÃ©es de 5 pages (modifiable dans le code).

### Option 2 : Dashboard interactif

Pour lancer le dashboard Streamlit :

```bash
streamlit run dashboard.py
```

Le dashboard s'ouvrira automatiquement dans votre navigateur par dÃ©faut.

### FonctionnalitÃ©s du Dashboard

1. **Charger des donnÃ©es existantes** : Utilise le fichier `books_data.csv` existant
2. **Nouveau scraping** : Lance un nouveau scraping avec un nombre de pages personnalisable
3. **Visualisations** : Explorez diffÃ©rents graphiques et analyses
4. **Filtrage** : Filtrez les livres par prix et notation
5. **Export** : TÃ©lÃ©chargez les donnÃ©es filtrÃ©es en CSV

## ğŸ“ Structure du Projet

```
webScrapingbooks/
â”‚
â”œâ”€â”€ scraper.py              # Script de web scraping
â”œâ”€â”€ dashboard.py            # Application Streamlit
â”œâ”€â”€ books_data.csv          # DonnÃ©es scrapÃ©es (gÃ©nÃ©rÃ©)
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ README.md              # Ce fichier
â”‚
â””â”€â”€ __pycache__/           # Cache Python (ignorÃ©)